<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>White Outline Scanner Test 4.0</title>
  <script src="https://docs.opencv.org/4.x/opencv.js" async></script>
  <style>
    body { margin:0; background:#000; color:white; font-family:system-ui; }
    .container { height:100dvh; display:flex; flex-direction:column; }
    .header { background:#7f2a8f; padding:3cqi; text-align:center; font-size:6cqi; }
    .content { flex:1; display:flex; flex-direction:column; align-items:center; padding:4cqi; gap:3cqi; }
    .camera-container { position:relative; width:90vw; max-width:520px; aspect-ratio:5/7; border-radius:16px; overflow:hidden; }
    #camera-preview { width:100%; height:100%; object-fit:cover; }
    #output-canvas { max-width:90vw; border:3px solid #333; border-radius:12px; background:#fff; box-shadow:0 4px 20px rgba(0,0,0,0.5); }
    .status { font-size:4.5cqi; text-align:center; margin:10px 0; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">White Outline Scanner Test 4.0</div>
    <div class="content">
      <p>Point camera at your notebook (full white border in frame!)</p>
      <div class="camera-container">
        <video id="camera-preview" autoplay playsinline muted></video>
      </div>
      <button id="snap-btn" style="display:none; padding:3cqi 8cqi; font-size:5.5cqi;">SNAP NOW</button>
      <canvas id="output-canvas"></canvas>
      <div id="status" class="status">Waiting for photo...</div>
    </div>
  </div>
  <script>
    console.log("=== WHITE OUTLINE SCANNER 4.0 LOADED ===");
    let stream = null;
    let video = document.getElementById('camera-preview');
    let outputCanvas = document.getElementById('output-canvas');
    let status = document.getElementById('status');
    
    async function startCamera() {
      stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
      video.srcObject = stream;
      video.onloadeddata = () => document.getElementById('snap-btn').style.display = 'block';
    }
    
    document.getElementById('snap-btn').onclick = () => {
      status.textContent = "Capturing photo...";
      const ctx = outputCanvas.getContext('2d');
      outputCanvas.width = video.videoWidth;
      outputCanvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      status.textContent = "Processing & warping white outline... (3-5 seconds)";
      setTimeout(() => {
        processWhiteOutline(outputCanvas);
      }, 100);
    };
    
    function orderPoints(pts) {
      let ordered = new Array(4);
      let minSum = Infinity, maxSum = -Infinity;
      let minDiff = Infinity, maxDiff = -Infinity;
      for (let p of pts) {
        let sum = p[0] + p[1];
        let diff = p[0] - p[1];
        if (sum < minSum) { minSum = sum; ordered[0] = p; } // TL
        if (sum > maxSum) { maxSum = sum; ordered[2] = p; } // BR
        if (diff < minDiff) { minDiff = diff; ordered[3] = p; } // BL
        if (diff > maxDiff) { maxDiff = diff; ordered[1] = p; } // TR
      }
      return ordered;
    }
    
    function processWhiteOutline(canvas) {
      try {
        let src = cv.imread(canvas);  // RGBA
        
        // Lenient white detection with blur for crisp edges
        let gray = new cv.Mat();
        let mask = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
        cv.threshold(gray, mask, 155, 255, cv.THRESH_BINARY);
        
        // Connect the outline, then thin slightly for tight corners
        let kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
        cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel, new cv.Point(-1, -1), 1);
        cv.dilate(mask, mask, kernel, new cv.Point(-1, -1), 6);
        cv.erode(mask, mask, kernel, new cv.Point(-1, -1), 2);  // Tighten for better corner snap
        
        // RETR_TREE for frame detection
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(mask, contours, hierarchy, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);
        
        let bestArea = 0;
        let bestApprox = null;
        let allAreas = [];
        let isFrame = false;
        
        for (let i = 0; i < contours.size(); i++) {
          let contour = contours.get(i);
          let area = cv.contourArea(contour);
          allAreas.push(area);
          if (area < 5000) continue;
          
          let hasChild = hierarchy.data32S[i * 4 + 2] !== -1;
          
          let targetContour = contour;  // Default outer
          let targetArea = area;
          if (hasChild) {
            let childIdx = hierarchy.data32S[i * 4 + 2];
            let child = contours.get(childIdx);
            targetArea = cv.contourArea(child);  // Use inner area for selection
            isFrame = true;
          }
          
          if (targetArea > bestArea) {
            // Approx poly for sharp corners (tighter than minAreaRect)
            let peri = cv.arcLength(targetContour, true);
            let approx = new cv.Mat();
            cv.approxPolyDP(targetContour, approx, 0.015 * peri, true);  // Tighter epsilon for exact corners
            
            if (approx.rows === 4) {
              bestApprox = approx.clone();
              bestArea = targetArea;
            } else {
              approx.delete();
            }
          }
        }
        
        // DEBUG - COPY AFTER SNAP
        console.log(`=== DEBUG 4.0 ===`);
        console.log(`Total contours: ${contours.size()}`);
        console.log(`Top 5 areas: ${allAreas.sort((a,b) => b - a).slice(0,5).map(a => Math.round(a))}`);
        console.log(`Best area: ${Math.round(bestArea)} | Frame: ${isFrame} | Approx points: ${bestApprox ? bestApprox.rows : 0}`);
        
        let minArea = Math.max(15000, (src.rows * src.cols) * 0.015);
        
        if (bestApprox && bestApprox.rows === 4 && bestArea > minArea) {
          status.textContent = `SUCCESS! Perfectly aligned warped notebook (Area: ${Math.round(bestArea)})`;
          
          // Extract 4 points from approx (outer-ish for border inclusion)
          let pts = [];
          for (let j = 0; j < 4; j++) {
            pts.push([bestApprox.data32F[j * 2], bestApprox.data32F[j * 2 + 1]]);
          }
          
          let ordered = orderPoints(pts);
          console.log(`Ordered corners: ${ordered.map(p => `(${Math.round(p[0])},${Math.round(p[1])})`).join(' → ')}`);
          
          // Compute size from quad, but force exact paper aspect (9.75 x 6.5)
          let paperWidth = 9.75;
          let paperHeight = 6.5;
          let paperRatio = paperWidth / paperHeight;  // 1.5
          
          // Use the larger dimension from the quad to set scale
          let quadWidth = Math.max(
            Math.hypot(ordered[1][0] - ordered[0][0], ordered[1][1] - ordered[0][1]),
            Math.hypot(ordered[2][0] - ordered[3][0], ordered[2][1] - ordered[3][1])
          );
          let quadHeight = Math.max(
            Math.hypot(ordered[1][0] - ordered[2][0], ordered[1][1] - ordered[2][1]),
            Math.hypot(ordered[0][0] - ordered[3][0], ordered[0][1] - ordered[3][1])
          );
          
          let dstWidth = Math.round(Math.max(quadWidth, quadHeight * paperRatio));
          let dstHeight = Math.round(dstWidth / paperRatio);
          console.log(`Forced paper aspect warp: ${dstWidth}x${dstHeight}`);
          
          // Perspective warp
          let srcPoints = new cv.Mat(4, 1, cv.CV_32FC2);
          let dstPoints = new cv.Mat(4, 1, cv.CV_32FC2);
          srcPoints.data32F.set([ordered[0][0], ordered[0][1], ordered[1][0], ordered[1][1], 
                                 ordered[2][0], ordered[2][1], ordered[3][0], ordered[3][1]]);
          dstPoints.data32F.set([0, 0, dstWidth, 0, dstWidth, dstHeight, 0, dstHeight]);
          
          let M = cv.getPerspectiveTransform(srcPoints, dstPoints);
          
          let warped = new cv.Mat();
          cv.warpPerspective(src, warped, M, new cv.Size(dstWidth, dstHeight), cv.INTER_LINEAR);
          
          // Upscale to preview
          let targetWidth = 800;
          let targetHeight = Math.round(targetWidth * (dstHeight / dstWidth));
          let resized = new cv.Mat();
          cv.resize(warped, resized, new cv.Size(targetWidth, targetHeight), 0, 0, cv.INTER_CUBIC);
          
          outputCanvas.width = targetWidth;
          outputCanvas.height = targetHeight;
          cv.imshow('output-canvas', resized);
          console.log('✅ Perfect alignment preview rendered!');
          
          // Cleanup
          srcPoints.delete(); dstPoints.delete(); M.delete();
          warped.delete(); resized.delete();
          bestApprox.delete();
        } else {
          status.textContent = `No strong outline (max area: ${Math.round(bestArea)}) — check console!`;
          cv.imshow('output-canvas', src);
          if (bestApprox) bestApprox.delete();
        }
        
        // Cleanup
        src.delete(); gray.delete(); mask.delete(); kernel.delete();
        contours.delete(); hierarchy.delete();
      } catch (e) {
        const errMsg = e ? (e.message || (typeof e === 'string' ? e : JSON.stringify(e) || 'unknown')) : 'unknown';
        status.textContent = `Error: ${errMsg}`;
        console.error('=== FULL ERROR ===', e);
        if (src) cv.imshow('output-canvas', src);
      }
    }
    
    window.onload = startCamera;
  </script>
</body>
</html>
